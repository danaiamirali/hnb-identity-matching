{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre Processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a notebook for intaking a raw data file, preprocessing it, and exporting it in a format in which it can easily be labeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/directoryident.tsv\", sep=\"\\t\")\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add unique ID column\n",
    "# Uses the row number of original csv file as unique ID\n",
    "df['Unique ID'] = df.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn all NaN values into empty strings\n",
    "df['address'] = df['address'].fillna(\" \")\n",
    "df['middle'] = df['middle'].fillna(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all columns to string\n",
    "df = df.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take sample of 5000\n",
    "df = df.sample(n=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse a singular dn field\n",
    "# Returns the uid in the dn\n",
    "def parse_dn(dn):\n",
    "    dn = dn.split(',')\n",
    "    dn = [x.split('=') for x in dn]\n",
    "    dn = {x[0].strip(): x[1].strip() for x in dn}\n",
    "    return dn[\"uid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to concatenate every value in the address \n",
    "# We want to concatenate all values inside curly braces\n",
    "def concat_address(address):\n",
    "    if address != ' ':\n",
    "        address = address.split('}:{')\n",
    "        try: \n",
    "            address = [x.split('=')[1] for x in address]\n",
    "        except:\n",
    "            return \"DELETE\"\n",
    "        address = ' '.join(address)\n",
    "    return address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use vectorization to set new values for dn and address columns\n",
    "df['dn'] = df['dn'].apply(parse_dn)\n",
    "df['address'] = df['address'].apply(concat_address)\n",
    "df['dob'] = df['dob'].apply(lambda x : x[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"DELETE\" in df['address'].values:\n",
    "    df = df[df['address'] != \"DELETE\"]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change column names\n",
    "df.columns = ['ID', 'Last Name', 'First Name', 'Middle Name', 'Date of Birth', 'Address', 'Unique ID']\n",
    "# Reorder columns\n",
    "df = df[['Unique ID', 'ID', 'First Name', 'Middle Name', 'Last Name', 'Date of Birth', 'Address']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 50 records from df into new df\n",
    "df_sample = df.sample(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove sampled records from df\n",
    "df = df.drop(df_sample.index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a sample df, we can now build a similarity measure df by comparing each record in the sample df with the other records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Levenshtein as lev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Returns normalized levenshtein distance between two strings\n",
    "\"\"\"\n",
    "def levenshtein_distance(\n",
    "        s1: str,\n",
    "        s2: str\n",
    ") -> int:\n",
    "    distance = lev.distance(s1, s2)\n",
    "    try:\n",
    "        return 1 - distance / float(max(len(s1), len(s2)))\n",
    "    except ZeroDivisionError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Returns Levenshtein distance between each field of two rows\n",
    "Assumes following format for rows:\n",
    "    row = pd.Series([First Name, Middle Name, Last Name, DOB, Address, ID])\n",
    "\"\"\"\n",
    "def row_similarity(\n",
    "        row_1: pd.Series, \n",
    "        df_2: pd.DataFrame\n",
    "    ) -> pd.DataFrame:\n",
    "\n",
    "    # Compute similarity measures for each column using Levenshtein distance\n",
    "    first_name_similarity = df_2['First Name'].apply(lambda x : levenshtein_distance(row_1['First Name'], x))\n",
    "    middle_name_similarity = df_2['Middle Name'].apply(lambda x : levenshtein_distance(row_1['Middle Name'], x))\n",
    "    last_name_similarity = df_2['Last Name'].apply(lambda x : levenshtein_distance(row_1['Last Name'], x))\n",
    "    dob_similarity = df_2['Date of Birth'].apply(lambda x : levenshtein_distance(row_1['Date of Birth'], x))\n",
    "    address_similarity = df_2['Address'].apply(lambda x : levenshtein_distance(row_1['Address'], x))\n",
    "    id_similarity = df_2['ID'].apply(lambda x : levenshtein_distance(row_1['ID'], x))\n",
    "\n",
    "    # Return DataFrame with similarity measures\n",
    "    return pd.DataFrame({\n",
    "        'UNIQ_ID1': row_1['Unique ID'],\n",
    "        'UNIQ_ID2': df_2['Unique ID'],\n",
    "        'ID1': row_1['ID'],\n",
    "        'ID2': df_2['ID'],\n",
    "        'ID Similarity': id_similarity,\n",
    "        'First Name 1' : row_1['First Name'],\n",
    "        'First Name 2' : df_2['First Name'],\n",
    "        'First Name Similarity': first_name_similarity,\n",
    "        'Middle Name 1' : row_1['Middle Name'],\n",
    "        'Middle Name 2' : df_2['Middle Name'],\n",
    "        'Middle Name Similarity': middle_name_similarity,\n",
    "        'Last Name 1' : row_1['Last Name'],\n",
    "        'Last Name 2' : df_2['Last Name'],\n",
    "        'Last Name Similarity': last_name_similarity,\n",
    "        'Date of Birth 1' : row_1['Date of Birth'],\n",
    "        'Date of Birth 2' : df_2['Date of Birth'],\n",
    "        'Date of Birth Similarity': dob_similarity,\n",
    "        'Address 1' : row_1['Address'],\n",
    "        'Address 2' : df_2['Address'],\n",
    "        'Address Similarity': address_similarity\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Builds similarity measure between records in two df\n",
    "Creates a new df from the two df with the following columns:\n",
    "    - ID1: ID of record in df1\n",
    "    - ID2: ID of record in df2\n",
    "    - First Name Similarity: Normalized levenshtein distance between first names\n",
    "    - Middle Name Similarity: Normalized levenshtein distance between middle names\n",
    "    - Last Name Similarity: Normalized levenshtein distance between last names\n",
    "    - Date of Birth Similarity: Normalized levenshtein distance between dates of birth\n",
    "    - Address Similarity: Normalized levenshtein distance between addresses\n",
    "    - ID Similarity: Normalized levenshtein distance between IDs\n",
    "\"\"\"\n",
    "def build_similarity_df (\n",
    "        df_1: pd.DataFrame,\n",
    "        df_2: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    new_df = pd.DataFrame(columns=[ 'UNIQ_ID1',\n",
    "                                    'UNIQ_ID2',\n",
    "                                    'ID1', \n",
    "                                   'ID2', \n",
    "                                   'ID Similarity',\n",
    "                                   'First Name 1',\n",
    "                                   'First Name 2',\n",
    "                                   'First Name Similarity', \n",
    "                                   'Middle Name 1',\n",
    "                                    'Middle Name 2',\n",
    "                                   'Middle Name Similarity',\n",
    "                                    'Last Name 1',\n",
    "                                    'Last Name 2', \n",
    "                                   'Last Name Similarity', \n",
    "                                    'Date of Birth 1',\n",
    "                                    'Date of Birth 2',\n",
    "                                   'Date of Birth Similarity', \n",
    "                                    'Address 1',\n",
    "                                    'Address 2',\n",
    "                                   'Address Similarity'])\n",
    "\n",
    "    # Convert ID columns to string\n",
    "    df_1[\"ID\"] = df_1[\"ID\"].astype(str)\n",
    "    df_2[\"ID\"] = df_2[\"ID\"].astype(str)\n",
    "\n",
    "    def apply_row_similarity(row, new_df):\n",
    "        sim = row_similarity(row, df_2)\n",
    "        new_df = pd.concat([new_df, sim], ignore_index=True)\n",
    "        return new_df\n",
    "\n",
    "    # Use vectorization to compute similarity between each row in df_1 and df_2\n",
    "    new_df = df_1.apply(apply_row_similarity, args=(new_df,), axis=1).reset_index(drop=True)\n",
    "\n",
    "    # New df is a series of dfs, so we need to concatenate them\n",
    "    new_df = pd.concat(new_df.to_list(), ignore_index=True)\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_df = build_similarity_df(df_sample,  df)\n",
    "similarity_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discretization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WPKID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wpkid_df = similarity_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# holds bin ranges for each similarity attribute\n",
    "bin_ranges = {'First Name Similarity' : [],\n",
    "        'Middle Name Similarity' : [],\n",
    "        'Last Name Similarity' : [],\n",
    "        'Date of Birth Similarity' : [],\n",
    "        'Address Similarity' : [],\n",
    "        'ID Similarity' : []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for solving systems of equations\n",
    "import sympy as sp \n",
    "import math"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "t = # of intervals<br>\n",
    "s = interval size<br>\n",
    "n = # of instances in training dataset<br>\n",
    "\n",
    "s * t = n<br>\n",
    "s - 30 = t<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WPKID function to solve for s and t given n, returns pair {s, t}\n",
    "def interval_size_and_num(n) -> tuple:\n",
    "    s, t = sp.symbols('s t')\n",
    "    equation1 = sp.Eq(s * t, n)\n",
    "    equation2 = sp.Eq(s - 30, t)  \n",
    "    solution = sp.solve((equation1, equation2), (s, t))\n",
    "    s_val = solution[0][1] * -1\n",
    "    t_val = solution[1][1]\n",
    "\n",
    "    s_int = math.floor(s_val)\n",
    "    t_int = math.floor(t_val)\n",
    "    return s_int, t_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes in a column and discretizes it, saving bin ranges\n",
    "def discretize_column(column, df):\n",
    "    # separate zeros from nonzeros\n",
    "    zeros_df = wpkid_df[wpkid_df[column] == 0].copy()\n",
    "    nonzeros_df = wpkid_df[wpkid_df[column] != 0].copy()\n",
    "\n",
    "    #get num_instances and num_intervals for nonzeros\n",
    "    num_instances = interval_size_and_num(len(nonzeros_df))[0]\n",
    "    num_intervals = interval_size_and_num(len(nonzeros_df))[1]\n",
    "\n",
    "    # get bin ranges for nonzeros\n",
    "    nonzeros_df[column], bin = pd.qcut(nonzeros_df[column], \n",
    "                                        q=num_intervals, \n",
    "                                        labels=False,\n",
    "                                        retbins=True,\n",
    "                                        duplicates='drop')\n",
    "    \n",
    "    #add 1 to every value to switch to index 1\n",
    "    nonzeros_df[column] = nonzeros_df[column] + 1\n",
    "\n",
    "    #save bin ranges\n",
    "    bin_ranges[column].extend(bin.tolist())\n",
    "\n",
    "    #recombine zero and nonzero dataframes\n",
    "    df.loc[df[column] == 0, column] = zeros_df[column]\n",
    "    df.loc[df[column] != 0, column] = nonzeros_df[column] \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wpkid_df = discretize_column('First Name Similarity', wpkid_df)\n",
    "wpkid_df = discretize_column('Middle Name Similarity', wpkid_df)\n",
    "wpkid_df = discretize_column('Last Name Similarity', wpkid_df)\n",
    "wpkid_df = discretize_column('Date of Birth Similarity', wpkid_df)\n",
    "wpkid_df = discretize_column('Address Similarity', wpkid_df)\n",
    "wpkid_df = discretize_column('ID Similarity', wpkid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert 0 at the beginning of each bin range\n",
    "for key in bin_ranges:\n",
    "    bin_ranges[key].insert(0, 0)\n",
    "\n",
    "# if last value in bin range is not 1.0, add it\n",
    "for key in bin_ranges:\n",
    "    if bin_ranges[key][-1] != 1.0:\n",
    "        bin_ranges[key].append(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Export for prototype.py\n",
    "\"\"\"\n",
    "import pickle\n",
    "\n",
    "# Create copy of bin ranges\n",
    "# Turn bin ranges value into an integer representing size of the bin\n",
    "with open('bin_ranges.pickle', 'wb') as handle:\n",
    "    pickle.dump(bin_ranges, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wpkid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in bin_ranges.items():\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export wpkid_df to csv \n",
    "wpkid_df.to_csv('data/sampleunlabeledident.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
