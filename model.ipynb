{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/synthetic_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Address</th>\n",
       "      <th>Date of Birth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>787879</td>\n",
       "      <td>Karen Hughes</td>\n",
       "      <td>668 Thompson Square, East Monicaburgh, OR 01361</td>\n",
       "      <td>07-18-1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>442995</td>\n",
       "      <td>Tracy George</td>\n",
       "      <td>013 Watson Prairie, North Mistyton, ME 96068</td>\n",
       "      <td>11-04-1977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>865957</td>\n",
       "      <td>Jennifer Patel</td>\n",
       "      <td>5787 Kim Summit Apt. 750, Janeport, MI 55669</td>\n",
       "      <td>04-24-2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>427670</td>\n",
       "      <td>Ashley Williams</td>\n",
       "      <td>32599 Tracy Flat, North Lisamouth, MA 38573</td>\n",
       "      <td>05-26-1951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>294077</td>\n",
       "      <td>Christopher Lee</td>\n",
       "      <td>PSC 4163, Box 9402, APO AP 88964</td>\n",
       "      <td>06-18-1941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID             Name                                          Address  \\\n",
       "0  787879     Karen Hughes  668 Thompson Square, East Monicaburgh, OR 01361   \n",
       "1  442995     Tracy George     013 Watson Prairie, North Mistyton, ME 96068   \n",
       "2  865957   Jennifer Patel     5787 Kim Summit Apt. 750, Janeport, MI 55669   \n",
       "3  427670  Ashley Williams      32599 Tracy Flat, North Lisamouth, MA 38573   \n",
       "4  294077  Christopher Lee                 PSC 4163, Box 9402, APO AP 88964   \n",
       "\n",
       "  Date of Birth  \n",
       "0    07-18-1995  \n",
       "1    11-04-1977  \n",
       "2    04-24-2004  \n",
       "3    05-26-1951  \n",
       "4    06-18-1941  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function to split name into first, middle, and last name\n",
    "\"\"\"\n",
    "def split_name(name):\n",
    "    name = name.split()\n",
    "    first_name = name[0]\n",
    "    last_name = name[-1]\n",
    "    middle_name = \" \".join(name[1:-1])\n",
    "    return first_name, middle_name, last_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split name into first, middle, and last name\n",
    "df['First Name'], df['Middle Name'], df['Last Name'] = zip(*df['Name'].map(split_name))\n",
    "# Remove Name column\n",
    "df.drop('Name', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder cols to put name cols in front\n",
    "df = df[['First Name', 'Middle Name', 'Last Name', 'Date of Birth', 'Address', 'ID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>First Name</th>\n",
       "      <th>Middle Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Date of Birth</th>\n",
       "      <th>Address</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Karen</td>\n",
       "      <td></td>\n",
       "      <td>Hughes</td>\n",
       "      <td>07-18-1995</td>\n",
       "      <td>668 Thompson Square, East Monicaburgh, OR 01361</td>\n",
       "      <td>787879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tracy</td>\n",
       "      <td></td>\n",
       "      <td>George</td>\n",
       "      <td>11-04-1977</td>\n",
       "      <td>013 Watson Prairie, North Mistyton, ME 96068</td>\n",
       "      <td>442995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jennifer</td>\n",
       "      <td></td>\n",
       "      <td>Patel</td>\n",
       "      <td>04-24-2004</td>\n",
       "      <td>5787 Kim Summit Apt. 750, Janeport, MI 55669</td>\n",
       "      <td>865957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ashley</td>\n",
       "      <td></td>\n",
       "      <td>Williams</td>\n",
       "      <td>05-26-1951</td>\n",
       "      <td>32599 Tracy Flat, North Lisamouth, MA 38573</td>\n",
       "      <td>427670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Christopher</td>\n",
       "      <td></td>\n",
       "      <td>Lee</td>\n",
       "      <td>06-18-1941</td>\n",
       "      <td>PSC 4163, Box 9402, APO AP 88964</td>\n",
       "      <td>294077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    First Name Middle Name Last Name Date of Birth  \\\n",
       "0        Karen                Hughes    07-18-1995   \n",
       "1        Tracy                George    11-04-1977   \n",
       "2     Jennifer                 Patel    04-24-2004   \n",
       "3       Ashley              Williams    05-26-1951   \n",
       "4  Christopher                   Lee    06-18-1941   \n",
       "\n",
       "                                           Address      ID  \n",
       "0  668 Thompson Square, East Monicaburgh, OR 01361  787879  \n",
       "1     013 Watson Prairie, North Mistyton, ME 96068  442995  \n",
       "2     5787 Kim Summit Apt. 750, Janeport, MI 55669  865957  \n",
       "3      32599 Tracy Flat, North Lisamouth, MA 38573  427670  \n",
       "4                 PSC 4163, Box 9402, APO AP 88964  294077  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample 200 records from dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 200 records from df into new df and remove them from the old df\n",
    "df_sample = df.sample(200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>First Name</th>\n",
       "      <th>Middle Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Date of Birth</th>\n",
       "      <th>Address</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>Mitchell</td>\n",
       "      <td></td>\n",
       "      <td>Fuller</td>\n",
       "      <td>04-25-1933</td>\n",
       "      <td>Unit 9627 Box 7329, DPO AE 51570</td>\n",
       "      <td>139323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>Glenn</td>\n",
       "      <td></td>\n",
       "      <td>Smith</td>\n",
       "      <td>03-28-1986</td>\n",
       "      <td>28706 Lindsey Light, Lake Lindseyview, MI 14764</td>\n",
       "      <td>357124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>Teresa</td>\n",
       "      <td></td>\n",
       "      <td>Prince</td>\n",
       "      <td>01-21-1948</td>\n",
       "      <td>05216 Antonio Green Apt. 839, South Rebeccasid...</td>\n",
       "      <td>836589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>Dennis</td>\n",
       "      <td></td>\n",
       "      <td>Allen</td>\n",
       "      <td>01-06-1987</td>\n",
       "      <td>481 Scott Locks, Lake Andrew, LA 24626</td>\n",
       "      <td>400425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>David</td>\n",
       "      <td></td>\n",
       "      <td>Miller</td>\n",
       "      <td>07-13-1984</td>\n",
       "      <td>12445 Tonya Key, South Denisechester, MA 95179</td>\n",
       "      <td>942665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    First Name Middle Name Last Name Date of Birth  \\\n",
       "408   Mitchell                Fuller    04-25-1933   \n",
       "669      Glenn                 Smith    03-28-1986   \n",
       "646     Teresa                Prince    01-21-1948   \n",
       "639     Dennis                 Allen    01-06-1987   \n",
       "491      David                Miller    07-13-1984   \n",
       "\n",
       "                                               Address      ID  \n",
       "408                   Unit 9627 Box 7329, DPO AE 51570  139323  \n",
       "669    28706 Lindsey Light, Lake Lindseyview, MI 14764  357124  \n",
       "646  05216 Antonio Green Apt. 839, South Rebeccasid...  836589  \n",
       "639             481 Scott Locks, Lake Andrew, LA 24626  400425  \n",
       "491     12445 Tonya Key, South Denisechester, MA 95179  942665  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity Measures"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a sample df, we can now build a similarity measure df by comparing each record in the sample df with the other records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Levenshtein as lev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Returns normalized levenshtein distance between two strings\n",
    "\"\"\"\n",
    "def levenshtein_distance(\n",
    "        s1: str,\n",
    "        s2: str\n",
    ") -> int:\n",
    "    distance = lev.distance(s1, s2)\n",
    "    try:\n",
    "        return 1 - distance / max(len(s1), len(s2))\n",
    "    except ZeroDivisionError:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Returns Levenshtein distance between each field of two rows\n",
    "Assumes following format for rows:\n",
    "    row = pd.Series([First Name, Middle Name, Last Name, DOB, Address, ID])\n",
    "\"\"\"\n",
    "def row_similarity (\n",
    "        row1: pd.Series,\n",
    "        row2: pd.Series\n",
    ") -> list:\n",
    "    similarities = []\n",
    "    for col in row1.index:\n",
    "        similarity = levenshtein_distance(str(row1[col]), str(row2[col]))\n",
    "        similarities.append(similarity)\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Builds similarity measure between records in two df\n",
    "Creates a new df from the two df with the following columns:\n",
    "    - ID1: ID of record in df1\n",
    "    - ID2: ID of record in df2\n",
    "    - First Name Similarity: Normalized levenshtein distance between first names\n",
    "    - Middle Name Similarity: Normalized levenshtein distance between middle names\n",
    "    - Last Name Similarity: Normalized levenshtein distance between last names\n",
    "    - Date of Birth Similarity: Normalized levenshtein distance between dates of birth\n",
    "    - Address Similarity: Normalized levenshtein distance between addresses\n",
    "    - ID Similarity: Normalized levenshtein distance between IDs\n",
    "\"\"\"\n",
    "def build_similarity_df (\n",
    "        df_1: pd.DataFrame,\n",
    "        df_2: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    new_df = pd.DataFrame(columns=['ID1', \n",
    "                                   'ID2', \n",
    "                                   'First Name Similarity', \n",
    "                                   'Middle Name Similarity', \n",
    "                                   'Last Name Similarity', \n",
    "                                   'Date of Birth Similarity', \n",
    "                                   'Address Similarity', \n",
    "                                   'ID Similarity'])\n",
    "    for index_1, row_1 in df_1.iterrows():\n",
    "        row = []\n",
    "        for index_2, row_2 in df_2.iterrows():\n",
    "            row.append(row_1['ID'])\n",
    "            row.append(row_2['ID'])\n",
    "            row += row_similarity(row_1, row_2)\n",
    "            # Append new row to new_df\n",
    "            new_df.loc[len(new_df)] = row\n",
    "            row.clear()\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\indexes\\base.py:3800\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3799\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3800\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3801\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:2263\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:2273\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 142104",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\amira\\OneDrive\\Documents\\GitHub\\Projects\\hnb-identity-matching\\model.ipynb Cell 18\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/amira/OneDrive/Documents/GitHub/Projects/hnb-identity-matching/model.ipynb#X63sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m similarity_df \u001b[39m=\u001b[39m build_similarity_df(df_sample,  df)\n",
      "\u001b[1;32mc:\\Users\\amira\\OneDrive\\Documents\\GitHub\\Projects\\hnb-identity-matching\\model.ipynb Cell 18\u001b[0m in \u001b[0;36mbuild_similarity_df\u001b[1;34m(df_1, df_2)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/amira/OneDrive/Documents/GitHub/Projects/hnb-identity-matching/model.ipynb#X63sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m         row \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m row_similarity(row_1, row_2)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/amira/OneDrive/Documents/GitHub/Projects/hnb-identity-matching/model.ipynb#X63sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m         \u001b[39m# Append new row to new_df\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/amira/OneDrive/Documents/GitHub/Projects/hnb-identity-matching/model.ipynb#X63sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m         new_df\u001b[39m.\u001b[39;49mloc[\u001b[39mlen\u001b[39;49m(new_df)] \u001b[39m=\u001b[39m row\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/amira/OneDrive/Documents/GitHub/Projects/hnb-identity-matching/model.ipynb#X63sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m         row\u001b[39m.\u001b[39mclear()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/amira/OneDrive/Documents/GitHub/Projects/hnb-identity-matching/model.ipynb#X63sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mreturn\u001b[39;00m new_df\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\indexing.py:815\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    814\u001b[0m     key \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mapply_if_callable(key, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj)\n\u001b[1;32m--> 815\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_setitem_indexer(key)\n\u001b[0;32m    816\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[0;32m    818\u001b[0m iloc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39miloc\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39miloc\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\indexing.py:704\u001b[0m, in \u001b[0;36m_LocationIndexer._get_setitem_indexer\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    700\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, \u001b[39mrange\u001b[39m):\n\u001b[0;32m    701\u001b[0m     \u001b[39m# GH#45479 test_loc_setitem_range_key\u001b[39;00m\n\u001b[0;32m    702\u001b[0m     key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m--> 704\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_convert_to_indexer(key, axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\indexing.py:1367\u001b[0m, in \u001b[0;36m_LocIndexer._convert_to_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1362\u001b[0m \u001b[39mif\u001b[39;00m is_scalar(key) \u001b[39mor\u001b[39;00m (\u001b[39misinstance\u001b[39m(labels, MultiIndex) \u001b[39mand\u001b[39;00m is_hashable(key)):\n\u001b[0;32m   1363\u001b[0m     \u001b[39m# Otherwise get_loc will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m   1364\u001b[0m \n\u001b[0;32m   1365\u001b[0m     \u001b[39m# if we are a label return me\u001b[39;00m\n\u001b[0;32m   1366\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1367\u001b[0m         \u001b[39mreturn\u001b[39;00m labels\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   1368\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mLookupError\u001b[39;00m:\n\u001b[0;32m   1369\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, \u001b[39mtuple\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(labels, MultiIndex):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\indexes\\base.py:3800\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3798\u001b[0m casted_key \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_indexer(key)\n\u001b[0;32m   3799\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3800\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3801\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m   3802\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "similarity_df = build_similarity_df(df_sample,  df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discretization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.models import BayesianModel\n",
    "from pgmpy.estimators import MaximumLikelihoodEstimator, BayesianEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Hierarchical Naive Bayes model\n",
    "model = BayesianModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level1 = ['Identity Match']\n",
    "level2 = ['Name Match', 'DOB Match', 'Address Match', 'ID Match']\n",
    "level3 = ['First Name Match', 'Middle Name Match', 'Last Name Match', 'DOB Similarity', 'Address Similarity', 'ID Similarity']\n",
    "level4 = ['First Name Similarity', 'Middle Name Similarity', 'Last Name Similarity']\n",
    "\n",
    "# Add Nodes\n",
    "model.add_nodes_from(level1)\n",
    "model.add_nodes_from(level2)\n",
    "model.add_nodes_from(level3)\n",
    "model.add_nodes_from(level4)\n",
    "\n",
    "# Add edges in most confusing way possible\n",
    "\n",
    "# Connect level1 with level2\n",
    "pairs = []\n",
    "for val in level2:\n",
    "    pairs.append(level1[0], val)\n",
    "model.add_edges_from(pairs)\n",
    "\n",
    "# Connect Name Match\n",
    "pairs.clear()\n",
    "for val in level3[0:3]:\n",
    "    pairs.append(level2[0], val)\n",
    "model.add_edges_from(pairs)\n",
    "\n",
    "# Connect DOB, Address, and ID Match with Similarity\n",
    "pairs.clear()\n",
    "for i in range(1, 4):\n",
    "    pairs.append(level2[i], level3[i + 2])\n",
    "model.add_edges_from(pairs)\n",
    "\n",
    "# Connect Name Matches with Similarity\n",
    "pairs.clear()\n",
    "for i in range(3):\n",
    "    pairs.append(level3[i], level4[i])\n",
    "model.add_edges_from(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate CPDs using Maximum Likelihood Estimation (MLE)\n",
    "estimator = MaximumLikelihoodEstimator(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the data\n",
    "model.fit(data, estimator=estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using the trained model\n",
    "# Assuming you have a test DataFrame 'test_data' with columns 'A', 'B', 'C', 'D', 'E'\n",
    "predictions = model.predict(test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
